{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qI5-QG5VFnvk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I could feel at the time. There was no way of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Take me now, baby, here as I am. Hold me close...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>These are. These are days you'll remember. Nev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A lie to say, \"O my mountain has coal veins an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trudging slowly over wet sand. Back to the ben...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Lyrics\n",
              "0  I could feel at the time. There was no way of ...\n",
              "1  Take me now, baby, here as I am. Hold me close...\n",
              "2  These are. These are days you'll remember. Nev...\n",
              "3  A lie to say, \"O my mountain has coal veins an...\n",
              "4  Trudging slowly over wet sand. Back to the ben..."
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "X = pd.read_csv(r'D:\\NLP\\Dataset_Full.csv')\n",
        "# Keeping only the neccessary columns\n",
        "X = X[['Lyrics']]\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sZx7Q8kTHNGR"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rock</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Genre\n",
              "0  Rock\n",
              "1  Rock\n",
              "2  Rock\n",
              "3  Rock\n",
              "4  Rock"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "y = pd.read_csv(r'D:\\NLP\\Dataset_Full.csv')\n",
        "# Keeping only the neccessary columns\n",
        "y = y[['Genre']]\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pop</th>\n",
              "      <th>Rock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pop  Rock\n",
              "0    0     1\n",
              "1    0     1\n",
              "2    0     1\n",
              "3    0     1\n",
              "4    0     1"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dropping the first column from status dataset\n",
        "status = pd.get_dummies(y['Genre'], drop_first = True)\n",
        "\n",
        "# Adding the status to the original y yframe\n",
        "y = pd.concat([y, status], axis = 1)\n",
        "\n",
        "# Dropping 'Property_Area' as we have created the dummies for it\n",
        "y.drop(['Genre'], axis = 1, inplace = True)\n",
        "\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pop</th>\n",
              "      <th>Rock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pop  Rock\n",
              "0    0     1\n",
              "1    0     1\n",
              "2    0     1\n",
              "3    0     1\n",
              "4    0     1"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I could feel at the time. There was no way of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Take me now, baby, here as I am. Hold me close...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>These are. These are days you'll remember. Nev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A lie to say, \"O my mountain has coal veins an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Trudging slowly over wet sand. Back to the ben...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Lyrics\n",
              "0  I could feel at the time. There was no way of ...\n",
              "1  Take me now, baby, here as I am. Hold me close...\n",
              "2  These are. These are days you'll remember. Nev...\n",
              "3  A lie to say, \"O my mountain has coal veins an...\n",
              "4  Trudging slowly over wet sand. Back to the ben..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Z6Mr_5YWHM-l"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "use= hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "aa=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9uj-fxxxHM8H"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300, dropout=0.5, recurrent_dropout=0.4,\n",
        "              input_shape=[1, 118272], return_sequences=True))\n",
        "    #model.add(LSTM(300, dropout=0.5, recurrent_dropout=0.4, return_sequences=True))\n",
        "    model.add(LSTM(200, dropout=0.5, recurrent_dropout=0.4, return_sequences=True))\n",
        "    model.add(LSTM(100, dropout=0.5, recurrent_dropout=0.4, return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dR3W43HHM5p",
        "outputId": "52f5422c-59da-455c-fda0-61c076a5af5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\welcome\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "#from gensim.models import Word2Vec\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PjV4cJipHM3B"
      },
      "outputs": [],
      "source": [
        "def essay_to_wordlist(essay_v, remove_stopwords):\n",
        "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
        "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
        "    words = essay_v.lower().split()\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "    return (words)\n",
        "def essay_to_sentences(essay_v, remove_stopwords):\n",
        "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    #tokennizer=PunktSentenceTokenizer(english.pickle)\n",
        "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append((raw_sentence))\n",
        "    #print(sentences)\n",
        "    return sentences\n",
        "def makeFeatureVec(words, num_features,n):\n",
        "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
        "    featureVec = np.zeros((n,num_features),dtype=\"float32\")\n",
        "    featureVec = np.add(featureVec,use(words))   \n",
        "    #print(featureVec.shape)     \n",
        "    #featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "def getAvgFeatureVecs(essays, num_features,aa):\n",
        "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features*231),dtype=\"float32\")\n",
        "    #essayFeatureVecs=[]\n",
        "    #print(num_features*96)\n",
        "    for essay in essays:\n",
        "        #essayFeatureVecs.insert(counter,makeFeatureVec(essay,num_features,aa[counter]))\n",
        "        arr=makeFeatureVec(essay, num_features,aa[counter]).flatten()\n",
        "        ss=(num_features*231)-len(arr)\n",
        "        arr1=np.pad(arr,(0,ss),'constant', constant_values=(0, 0))\n",
        "        #print(np.add(arr1,np.zeros(num_features*np.max(aa))))\n",
        "        essayFeatureVecs[counter] = np.add(arr1,np.zeros((num_features*231),dtype=\"float\"))\n",
        "        #makeFeatureVec(essay, num_features,aa[counter]).flatten()\n",
        "        #print(essayFeatureVecs[0])\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPrz2r0AHlEc",
        "outputId": "42b2f8e9-a1cc-43c1-f0dc-b7434af2c71a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "197\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1, 300)            142287600 \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 142,851,170\n",
            "Trainable params: 142,851,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/35\n",
            "38/38 [==============================] - 36s 812ms/step - loss: 0.5442 - accuracy: 0.6405 - val_loss: 0.5496 - val_accuracy: 0.6533\n",
            "Epoch 2/35\n",
            "38/38 [==============================] - 30s 781ms/step - loss: 0.5927 - accuracy: 0.5688 - val_loss: 0.5475 - val_accuracy: 0.6734\n",
            "Epoch 3/35\n",
            "38/38 [==============================] - 30s 779ms/step - loss: 0.5209 - accuracy: 0.6938 - val_loss: 0.4678 - val_accuracy: 0.7538\n",
            "Epoch 4/35\n",
            "38/38 [==============================] - 30s 779ms/step - loss: 0.3575 - accuracy: 0.8238 - val_loss: 0.5474 - val_accuracy: 0.7504\n",
            "Epoch 5/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.2868 - accuracy: 0.8641 - val_loss: 0.5764 - val_accuracy: 0.7638\n",
            "Epoch 6/35\n",
            "38/38 [==============================] - 30s 798ms/step - loss: 0.2547 - accuracy: 0.8758 - val_loss: 0.5798 - val_accuracy: 0.7755\n",
            "Epoch 7/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.2446 - accuracy: 0.8767 - val_loss: 0.5394 - val_accuracy: 0.7822\n",
            "Epoch 8/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.2033 - accuracy: 0.8989 - val_loss: 0.5624 - val_accuracy: 0.7839\n",
            "Epoch 9/35\n",
            "38/38 [==============================] - 30s 783ms/step - loss: 0.2043 - accuracy: 0.9090 - val_loss: 0.6017 - val_accuracy: 0.7822\n",
            "Epoch 10/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.1680 - accuracy: 0.9320 - val_loss: 0.5596 - val_accuracy: 0.7906\n",
            "Epoch 11/35\n",
            "38/38 [==============================] - 30s 788ms/step - loss: 0.1711 - accuracy: 0.9153 - val_loss: 0.6794 - val_accuracy: 0.7822\n",
            "Epoch 12/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.1662 - accuracy: 0.9304 - val_loss: 0.5881 - val_accuracy: 0.7923\n",
            "Epoch 13/35\n",
            "38/38 [==============================] - 30s 787ms/step - loss: 0.1466 - accuracy: 0.9329 - val_loss: 0.7509 - val_accuracy: 0.7889\n",
            "Epoch 14/35\n",
            "38/38 [==============================] - 30s 786ms/step - loss: 0.1475 - accuracy: 0.9409 - val_loss: 0.6429 - val_accuracy: 0.7923\n",
            "Epoch 15/35\n",
            "38/38 [==============================] - 30s 786ms/step - loss: 0.1420 - accuracy: 0.9425 - val_loss: 0.6585 - val_accuracy: 0.7856\n",
            "Epoch 16/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1429 - accuracy: 0.9413 - val_loss: 0.6903 - val_accuracy: 0.7839\n",
            "Epoch 17/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1504 - accuracy: 0.9341 - val_loss: 0.6589 - val_accuracy: 0.7755\n",
            "Epoch 18/35\n",
            "38/38 [==============================] - 30s 792ms/step - loss: 0.1296 - accuracy: 0.9522 - val_loss: 0.6892 - val_accuracy: 0.7806\n",
            "Epoch 19/35\n",
            "38/38 [==============================] - 30s 785ms/step - loss: 0.1368 - accuracy: 0.9425 - val_loss: 0.6693 - val_accuracy: 0.7923\n",
            "Epoch 20/35\n",
            "38/38 [==============================] - 30s 787ms/step - loss: 0.1281 - accuracy: 0.9480 - val_loss: 0.6891 - val_accuracy: 0.7772\n",
            "Epoch 21/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.1335 - accuracy: 0.9492 - val_loss: 0.6753 - val_accuracy: 0.7772\n",
            "Epoch 22/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.1327 - accuracy: 0.9471 - val_loss: 0.7192 - val_accuracy: 0.7889\n",
            "Epoch 23/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.1216 - accuracy: 0.9551 - val_loss: 0.6573 - val_accuracy: 0.7739\n",
            "Epoch 24/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.1378 - accuracy: 0.9463 - val_loss: 0.7333 - val_accuracy: 0.7906\n",
            "Epoch 25/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1182 - accuracy: 0.9560 - val_loss: 0.6779 - val_accuracy: 0.7806\n",
            "Epoch 26/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.1107 - accuracy: 0.9576 - val_loss: 0.7324 - val_accuracy: 0.7923\n",
            "Epoch 27/35\n",
            "38/38 [==============================] - 30s 788ms/step - loss: 0.1155 - accuracy: 0.9589 - val_loss: 0.7092 - val_accuracy: 0.7906\n",
            "Epoch 28/35\n",
            "38/38 [==============================] - 30s 788ms/step - loss: 0.1129 - accuracy: 0.9509 - val_loss: 0.5858 - val_accuracy: 0.7806\n",
            "Epoch 29/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.1203 - accuracy: 0.9409 - val_loss: 0.7313 - val_accuracy: 0.7739\n",
            "Epoch 30/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.1162 - accuracy: 0.9467 - val_loss: 0.6859 - val_accuracy: 0.7822\n",
            "Epoch 31/35\n",
            "38/38 [==============================] - 30s 788ms/step - loss: 0.1046 - accuracy: 0.9543 - val_loss: 0.7425 - val_accuracy: 0.7755\n",
            "Epoch 32/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.0970 - accuracy: 0.9501 - val_loss: 0.7356 - val_accuracy: 0.7806\n",
            "Epoch 33/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.1098 - accuracy: 0.9463 - val_loss: 0.7297 - val_accuracy: 0.7822\n",
            "Epoch 34/35\n",
            "38/38 [==============================] - 31s 809ms/step - loss: 0.0947 - accuracy: 0.9539 - val_loss: 0.6665 - val_accuracy: 0.7722\n",
            "Epoch 35/35\n",
            "38/38 [==============================] - 30s 798ms/step - loss: 0.1055 - accuracy: 0.9341 - val_loss: 0.6857 - val_accuracy: 0.7789\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "231\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 1, 300)            142287600 \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 142,851,170\n",
            "Trainable params: 142,851,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/35\n",
            "38/38 [==============================] - 37s 834ms/step - loss: 0.5518 - accuracy: 0.6233 - val_loss: 0.5606 - val_accuracy: 0.6533\n",
            "Epoch 2/35\n",
            "38/38 [==============================] - 31s 809ms/step - loss: 0.6075 - accuracy: 0.5411 - val_loss: 0.5629 - val_accuracy: 0.6432\n",
            "Epoch 3/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.6740 - accuracy: 0.5180 - val_loss: 0.5627 - val_accuracy: 0.6466\n",
            "Epoch 4/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.6615 - accuracy: 0.5243 - val_loss: 0.5616 - val_accuracy: 0.6734\n",
            "Epoch 5/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.6206 - accuracy: 0.5520 - val_loss: 0.5369 - val_accuracy: 0.6868\n",
            "Epoch 6/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.5887 - accuracy: 0.5982 - val_loss: 0.5455 - val_accuracy: 0.6717\n",
            "Epoch 7/35\n",
            "38/38 [==============================] - 30s 796ms/step - loss: 0.5983 - accuracy: 0.5860 - val_loss: 0.5312 - val_accuracy: 0.7018\n",
            "Epoch 8/35\n",
            "38/38 [==============================] - 31s 807ms/step - loss: 0.5454 - accuracy: 0.6409 - val_loss: 0.5143 - val_accuracy: 0.7085\n",
            "Epoch 9/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.4933 - accuracy: 0.6867 - val_loss: 0.4506 - val_accuracy: 0.7923\n",
            "Epoch 10/35\n",
            "38/38 [==============================] - 29s 776ms/step - loss: 0.3836 - accuracy: 0.7982 - val_loss: 0.4949 - val_accuracy: 0.7521\n",
            "Epoch 11/35\n",
            "38/38 [==============================] - 29s 775ms/step - loss: 0.3218 - accuracy: 0.8083 - val_loss: 0.4428 - val_accuracy: 0.8040\n",
            "Epoch 12/35\n",
            "38/38 [==============================] - 29s 777ms/step - loss: 0.2575 - accuracy: 0.8377 - val_loss: 0.4671 - val_accuracy: 0.8141\n",
            "Epoch 13/35\n",
            "38/38 [==============================] - 30s 780ms/step - loss: 0.2090 - accuracy: 0.8607 - val_loss: 0.5202 - val_accuracy: 0.8258\n",
            "Epoch 14/35\n",
            "38/38 [==============================] - 29s 775ms/step - loss: 0.1904 - accuracy: 0.8654 - val_loss: 0.5274 - val_accuracy: 0.8057\n",
            "Epoch 15/35\n",
            "38/38 [==============================] - 30s 776ms/step - loss: 0.1594 - accuracy: 0.8695 - val_loss: 0.5550 - val_accuracy: 0.8090\n",
            "Epoch 16/35\n",
            "38/38 [==============================] - 31s 809ms/step - loss: 0.1543 - accuracy: 0.8595 - val_loss: 0.5477 - val_accuracy: 0.8107\n",
            "Epoch 17/35\n",
            "38/38 [==============================] - 31s 805ms/step - loss: 0.1247 - accuracy: 0.8725 - val_loss: 0.5740 - val_accuracy: 0.8191\n",
            "Epoch 18/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.1112 - accuracy: 0.8826 - val_loss: 0.6419 - val_accuracy: 0.8208\n",
            "Epoch 19/35\n",
            "38/38 [==============================] - 30s 787ms/step - loss: 0.1067 - accuracy: 0.8654 - val_loss: 0.6208 - val_accuracy: 0.8191\n",
            "Epoch 20/35\n",
            "38/38 [==============================] - 30s 787ms/step - loss: 0.0920 - accuracy: 0.8679 - val_loss: 0.6309 - val_accuracy: 0.8208\n",
            "Epoch 21/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.0920 - accuracy: 0.8691 - val_loss: 0.6010 - val_accuracy: 0.8275\n",
            "Epoch 22/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.0825 - accuracy: 0.8817 - val_loss: 0.6187 - val_accuracy: 0.8224\n",
            "Epoch 23/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.0797 - accuracy: 0.8872 - val_loss: 0.6328 - val_accuracy: 0.8258\n",
            "Epoch 24/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.0729 - accuracy: 0.8800 - val_loss: 0.6562 - val_accuracy: 0.8258\n",
            "Epoch 25/35\n",
            "38/38 [==============================] - 30s 786ms/step - loss: 0.0591 - accuracy: 0.8884 - val_loss: 0.6965 - val_accuracy: 0.8174\n",
            "Epoch 26/35\n",
            "38/38 [==============================] - 30s 783ms/step - loss: 0.0702 - accuracy: 0.8775 - val_loss: 0.6986 - val_accuracy: 0.8258\n",
            "Epoch 27/35\n",
            "38/38 [==============================] - 30s 785ms/step - loss: 0.0516 - accuracy: 0.8901 - val_loss: 0.7341 - val_accuracy: 0.8325\n",
            "Epoch 28/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.0699 - accuracy: 0.8788 - val_loss: 0.6868 - val_accuracy: 0.8291\n",
            "Epoch 29/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.0669 - accuracy: 0.8826 - val_loss: 0.6329 - val_accuracy: 0.8308\n",
            "Epoch 30/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.0869 - accuracy: 0.8901 - val_loss: 0.7068 - val_accuracy: 0.8342\n",
            "Epoch 31/35\n",
            "38/38 [==============================] - 30s 792ms/step - loss: 0.0682 - accuracy: 0.8809 - val_loss: 0.5886 - val_accuracy: 0.8174\n",
            "Epoch 32/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.0740 - accuracy: 0.8725 - val_loss: 0.7061 - val_accuracy: 0.8275\n",
            "Epoch 33/35\n",
            "38/38 [==============================] - 30s 792ms/step - loss: 0.0598 - accuracy: 0.8842 - val_loss: 0.7094 - val_accuracy: 0.8224\n",
            "Epoch 34/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.0557 - accuracy: 0.8880 - val_loss: 0.7356 - val_accuracy: 0.8258\n",
            "Epoch 35/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.0575 - accuracy: 0.8708 - val_loss: 0.6935 - val_accuracy: 0.8007\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "231\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 1, 300)            142287600 \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 142,851,170\n",
            "Trainable params: 142,851,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/35\n",
            "38/38 [==============================] - 35s 806ms/step - loss: 0.5305 - accuracy: 0.6495 - val_loss: 0.5569 - val_accuracy: 0.6549\n",
            "Epoch 2/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.5245 - accuracy: 0.6419 - val_loss: 0.5156 - val_accuracy: 0.7085\n",
            "Epoch 3/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.3685 - accuracy: 0.8088 - val_loss: 0.5042 - val_accuracy: 0.7538\n",
            "Epoch 4/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.2934 - accuracy: 0.8516 - val_loss: 0.5447 - val_accuracy: 0.7621\n",
            "Epoch 5/35\n",
            "38/38 [==============================] - 30s 798ms/step - loss: 0.2672 - accuracy: 0.8725 - val_loss: 0.5110 - val_accuracy: 0.7839\n",
            "Epoch 6/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.2263 - accuracy: 0.8922 - val_loss: 0.5603 - val_accuracy: 0.7672\n",
            "Epoch 7/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.2120 - accuracy: 0.8994 - val_loss: 0.5710 - val_accuracy: 0.7722\n",
            "Epoch 8/35\n",
            "38/38 [==============================] - 30s 792ms/step - loss: 0.2103 - accuracy: 0.8956 - val_loss: 0.6101 - val_accuracy: 0.7672\n",
            "Epoch 9/35\n",
            "38/38 [==============================] - 30s 798ms/step - loss: 0.1895 - accuracy: 0.9002 - val_loss: 0.6240 - val_accuracy: 0.7705\n",
            "Epoch 10/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.1939 - accuracy: 0.9119 - val_loss: 0.6898 - val_accuracy: 0.7789\n",
            "Epoch 11/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1702 - accuracy: 0.9212 - val_loss: 0.6713 - val_accuracy: 0.7806\n",
            "Epoch 12/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1581 - accuracy: 0.9254 - val_loss: 0.6530 - val_accuracy: 0.7940\n",
            "Epoch 13/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1515 - accuracy: 0.9279 - val_loss: 0.6694 - val_accuracy: 0.7739\n",
            "Epoch 14/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.1584 - accuracy: 0.9358 - val_loss: 0.6386 - val_accuracy: 0.7722\n",
            "Epoch 15/35\n",
            "38/38 [==============================] - 30s 796ms/step - loss: 0.1340 - accuracy: 0.9363 - val_loss: 0.6887 - val_accuracy: 0.7672\n",
            "Epoch 16/35\n",
            "38/38 [==============================] - 30s 792ms/step - loss: 0.1375 - accuracy: 0.9400 - val_loss: 0.6595 - val_accuracy: 0.7621\n",
            "Epoch 17/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1327 - accuracy: 0.9413 - val_loss: 0.6682 - val_accuracy: 0.7772\n",
            "Epoch 18/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.1362 - accuracy: 0.9312 - val_loss: 0.6800 - val_accuracy: 0.7806\n",
            "Epoch 19/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.1192 - accuracy: 0.9442 - val_loss: 0.7065 - val_accuracy: 0.7755\n",
            "Epoch 20/35\n",
            "38/38 [==============================] - 30s 792ms/step - loss: 0.1244 - accuracy: 0.9442 - val_loss: 0.6896 - val_accuracy: 0.7755\n",
            "Epoch 21/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.1214 - accuracy: 0.9447 - val_loss: 0.6754 - val_accuracy: 0.7806\n",
            "Epoch 22/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.1226 - accuracy: 0.9480 - val_loss: 0.6149 - val_accuracy: 0.7755\n",
            "Epoch 23/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.1276 - accuracy: 0.9455 - val_loss: 0.7209 - val_accuracy: 0.7822\n",
            "Epoch 24/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.1133 - accuracy: 0.9522 - val_loss: 0.6971 - val_accuracy: 0.7739\n",
            "Epoch 25/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1178 - accuracy: 0.9480 - val_loss: 0.8303 - val_accuracy: 0.7789\n",
            "Epoch 26/35\n",
            "38/38 [==============================] - 30s 796ms/step - loss: 0.1262 - accuracy: 0.9459 - val_loss: 0.7135 - val_accuracy: 0.7789\n",
            "Epoch 27/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.1229 - accuracy: 0.9493 - val_loss: 0.7412 - val_accuracy: 0.7873\n",
            "Epoch 28/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.1034 - accuracy: 0.9568 - val_loss: 0.7577 - val_accuracy: 0.7806\n",
            "Epoch 29/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1227 - accuracy: 0.9497 - val_loss: 0.7749 - val_accuracy: 0.7789\n",
            "Epoch 30/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1284 - accuracy: 0.9463 - val_loss: 0.6450 - val_accuracy: 0.7772\n",
            "Epoch 31/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.1393 - accuracy: 0.9430 - val_loss: 0.6193 - val_accuracy: 0.7822\n",
            "Epoch 32/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.1114 - accuracy: 0.9589 - val_loss: 0.6665 - val_accuracy: 0.7822\n",
            "Epoch 33/35\n",
            "38/38 [==============================] - 30s 796ms/step - loss: 0.1089 - accuracy: 0.9547 - val_loss: 0.7577 - val_accuracy: 0.7822\n",
            "Epoch 34/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.1179 - accuracy: 0.9514 - val_loss: 0.6838 - val_accuracy: 0.7755\n",
            "Epoch 35/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.1084 - accuracy: 0.9526 - val_loss: 0.7145 - val_accuracy: 0.7755\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "231\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 1, 300)            142287600 \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_15 (LSTM)              (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 142,851,170\n",
            "Trainable params: 142,851,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/35\n",
            "38/38 [==============================] - 36s 814ms/step - loss: 0.5423 - accuracy: 0.6331 - val_loss: 0.5818 - val_accuracy: 0.6482\n",
            "Epoch 2/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.5934 - accuracy: 0.5287 - val_loss: 0.5808 - val_accuracy: 0.6415\n",
            "Epoch 3/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.6167 - accuracy: 0.5354 - val_loss: 0.5905 - val_accuracy: 0.6533\n",
            "Epoch 4/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.6135 - accuracy: 0.5363 - val_loss: 0.5769 - val_accuracy: 0.6516\n",
            "Epoch 5/35\n",
            "38/38 [==============================] - 30s 798ms/step - loss: 0.5927 - accuracy: 0.5950 - val_loss: 0.5385 - val_accuracy: 0.7002\n",
            "Epoch 6/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.5155 - accuracy: 0.6964 - val_loss: 0.5411 - val_accuracy: 0.6968\n",
            "Epoch 7/35\n",
            "38/38 [==============================] - 30s 796ms/step - loss: 0.4094 - accuracy: 0.7853 - val_loss: 0.4918 - val_accuracy: 0.7420\n",
            "Epoch 8/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.3285 - accuracy: 0.8440 - val_loss: 0.4986 - val_accuracy: 0.7839\n",
            "Epoch 9/35\n",
            "38/38 [==============================] - 30s 799ms/step - loss: 0.2627 - accuracy: 0.8721 - val_loss: 0.5497 - val_accuracy: 0.7772\n",
            "Epoch 10/35\n",
            "38/38 [==============================] - 30s 792ms/step - loss: 0.2267 - accuracy: 0.9010 - val_loss: 0.5771 - val_accuracy: 0.7822\n",
            "Epoch 11/35\n",
            "38/38 [==============================] - 30s 796ms/step - loss: 0.2185 - accuracy: 0.9048 - val_loss: 0.5498 - val_accuracy: 0.7806\n",
            "Epoch 12/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.1951 - accuracy: 0.9161 - val_loss: 0.5372 - val_accuracy: 0.7722\n",
            "Epoch 13/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.1900 - accuracy: 0.9262 - val_loss: 0.5696 - val_accuracy: 0.7655\n",
            "Epoch 14/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.1684 - accuracy: 0.9346 - val_loss: 0.5773 - val_accuracy: 0.7806\n",
            "Epoch 15/35\n",
            "38/38 [==============================] - 30s 789ms/step - loss: 0.1638 - accuracy: 0.9375 - val_loss: 0.5619 - val_accuracy: 0.7856\n",
            "Epoch 16/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1555 - accuracy: 0.9325 - val_loss: 0.6700 - val_accuracy: 0.7906\n",
            "Epoch 17/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1472 - accuracy: 0.9174 - val_loss: 0.6413 - val_accuracy: 0.7822\n",
            "Epoch 18/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1197 - accuracy: 0.9338 - val_loss: 0.6427 - val_accuracy: 0.7755\n",
            "Epoch 19/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.1258 - accuracy: 0.9233 - val_loss: 0.6315 - val_accuracy: 0.7956\n",
            "Epoch 20/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.1160 - accuracy: 0.9216 - val_loss: 0.6707 - val_accuracy: 0.7822\n",
            "Epoch 21/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.0949 - accuracy: 0.9363 - val_loss: 0.6419 - val_accuracy: 0.7873\n",
            "Epoch 22/35\n",
            "38/38 [==============================] - 30s 797ms/step - loss: 0.0914 - accuracy: 0.9249 - val_loss: 0.7011 - val_accuracy: 0.7822\n",
            "Epoch 23/35\n",
            "38/38 [==============================] - 30s 790ms/step - loss: 0.0848 - accuracy: 0.9182 - val_loss: 0.7224 - val_accuracy: 0.7856\n",
            "Epoch 24/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.0712 - accuracy: 0.9195 - val_loss: 0.7296 - val_accuracy: 0.7789\n",
            "Epoch 25/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.0886 - accuracy: 0.9157 - val_loss: 0.7662 - val_accuracy: 0.7956\n",
            "Epoch 26/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.0675 - accuracy: 0.9241 - val_loss: 0.7982 - val_accuracy: 0.7621\n",
            "Epoch 27/35\n",
            "38/38 [==============================] - 30s 791ms/step - loss: 0.0670 - accuracy: 0.9153 - val_loss: 0.7324 - val_accuracy: 0.7705\n",
            "Epoch 28/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.0713 - accuracy: 0.9149 - val_loss: 0.7662 - val_accuracy: 0.8023\n",
            "Epoch 29/35\n",
            "38/38 [==============================] - 30s 796ms/step - loss: 0.0626 - accuracy: 0.9078 - val_loss: 0.7824 - val_accuracy: 0.8007\n",
            "Epoch 30/35\n",
            "38/38 [==============================] - 30s 796ms/step - loss: 0.0481 - accuracy: 0.9170 - val_loss: 0.7561 - val_accuracy: 0.7923\n",
            "Epoch 31/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.0583 - accuracy: 0.9107 - val_loss: 0.7649 - val_accuracy: 0.7856\n",
            "Epoch 32/35\n",
            "38/38 [==============================] - 30s 794ms/step - loss: 0.0450 - accuracy: 0.9178 - val_loss: 0.8564 - val_accuracy: 0.7956\n",
            "Epoch 33/35\n",
            "38/38 [==============================] - 30s 795ms/step - loss: 0.0503 - accuracy: 0.9086 - val_loss: 0.8725 - val_accuracy: 0.7822\n",
            "Epoch 34/35\n",
            "38/38 [==============================] - 30s 793ms/step - loss: 0.0557 - accuracy: 0.9086 - val_loss: 0.8148 - val_accuracy: 0.7621\n",
            "Epoch 35/35\n",
            "38/38 [==============================] - 30s 792ms/step - loss: 0.0468 - accuracy: 0.9182 - val_loss: 0.8353 - val_accuracy: 0.7806\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "231\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_16 (LSTM)              (None, 1, 300)            142287600 \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_18 (LSTM)              (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_19 (LSTM)              (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 142,851,170\n",
            "Trainable params: 142,851,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/35\n",
            "38/38 [==============================] - 39s 901ms/step - loss: 0.5443 - accuracy: 0.6189 - val_loss: 0.5881 - val_accuracy: 0.6583\n",
            "Epoch 2/35\n",
            "38/38 [==============================] - 35s 927ms/step - loss: 0.5997 - accuracy: 0.5358 - val_loss: 0.5829 - val_accuracy: 0.6365\n",
            "Epoch 3/35\n",
            "38/38 [==============================] - 35s 919ms/step - loss: 0.6226 - accuracy: 0.5241 - val_loss: 0.5833 - val_accuracy: 0.6365\n",
            "Epoch 4/35\n",
            "38/38 [==============================] - 35s 913ms/step - loss: 0.6013 - accuracy: 0.5396 - val_loss: 0.5831 - val_accuracy: 0.6399\n",
            "Epoch 5/35\n",
            "38/38 [==============================] - 35s 910ms/step - loss: 0.6280 - accuracy: 0.5124 - val_loss: 0.5850 - val_accuracy: 0.6399\n",
            "Epoch 6/35\n",
            "38/38 [==============================] - 35s 924ms/step - loss: 0.6427 - accuracy: 0.5136 - val_loss: 0.5824 - val_accuracy: 0.6415\n",
            "Epoch 7/35\n",
            "38/38 [==============================] - 35s 916ms/step - loss: 0.6148 - accuracy: 0.5392 - val_loss: 0.5805 - val_accuracy: 0.6449\n",
            "Epoch 8/35\n",
            "38/38 [==============================] - 35s 915ms/step - loss: 0.6240 - accuracy: 0.5354 - val_loss: 0.5702 - val_accuracy: 0.6784\n",
            "Epoch 9/35\n",
            "38/38 [==============================] - 35s 915ms/step - loss: 0.5726 - accuracy: 0.6277 - val_loss: 0.5392 - val_accuracy: 0.7069\n",
            "Epoch 10/35\n",
            "38/38 [==============================] - 35s 914ms/step - loss: 0.4955 - accuracy: 0.7086 - val_loss: 0.5158 - val_accuracy: 0.7236\n",
            "Epoch 11/35\n",
            "38/38 [==============================] - 35s 924ms/step - loss: 0.4015 - accuracy: 0.7816 - val_loss: 0.5578 - val_accuracy: 0.7521\n",
            "Epoch 12/35\n",
            "38/38 [==============================] - 35s 928ms/step - loss: 0.3371 - accuracy: 0.8273 - val_loss: 0.5139 - val_accuracy: 0.7688\n",
            "Epoch 13/35\n",
            "38/38 [==============================] - 35s 926ms/step - loss: 0.2793 - accuracy: 0.8646 - val_loss: 0.5742 - val_accuracy: 0.7688\n",
            "Epoch 14/35\n",
            "38/38 [==============================] - 35s 917ms/step - loss: 0.2532 - accuracy: 0.8746 - val_loss: 0.5537 - val_accuracy: 0.7655\n",
            "Epoch 15/35\n",
            "38/38 [==============================] - 35s 915ms/step - loss: 0.2130 - accuracy: 0.8935 - val_loss: 0.6067 - val_accuracy: 0.7839\n",
            "Epoch 16/35\n",
            "38/38 [==============================] - 35s 914ms/step - loss: 0.2215 - accuracy: 0.8860 - val_loss: 0.5765 - val_accuracy: 0.7772\n",
            "Epoch 17/35\n",
            "38/38 [==============================] - 35s 913ms/step - loss: 0.2009 - accuracy: 0.8843 - val_loss: 0.5898 - val_accuracy: 0.7906\n",
            "Epoch 18/35\n",
            "38/38 [==============================] - 35s 911ms/step - loss: 0.1704 - accuracy: 0.9027 - val_loss: 0.6496 - val_accuracy: 0.7839\n",
            "Epoch 19/35\n",
            "38/38 [==============================] - 35s 921ms/step - loss: 0.1564 - accuracy: 0.8901 - val_loss: 0.6433 - val_accuracy: 0.7789\n",
            "Epoch 20/35\n",
            "38/38 [==============================] - 36s 945ms/step - loss: 0.1547 - accuracy: 0.8851 - val_loss: 0.6358 - val_accuracy: 0.7923\n",
            "Epoch 21/35\n",
            "38/38 [==============================] - 36s 941ms/step - loss: 0.1371 - accuracy: 0.8918 - val_loss: 0.6597 - val_accuracy: 0.7789\n",
            "Epoch 22/35\n",
            "38/38 [==============================] - 35s 934ms/step - loss: 0.1322 - accuracy: 0.8784 - val_loss: 0.6143 - val_accuracy: 0.7923\n",
            "Epoch 23/35\n",
            "38/38 [==============================] - 35s 931ms/step - loss: 0.1224 - accuracy: 0.8948 - val_loss: 0.6771 - val_accuracy: 0.7906\n",
            "Epoch 24/35\n",
            "38/38 [==============================] - 36s 935ms/step - loss: 0.1258 - accuracy: 0.8998 - val_loss: 0.6891 - val_accuracy: 0.7822\n",
            "Epoch 25/35\n",
            "38/38 [==============================] - 35s 927ms/step - loss: 0.0968 - accuracy: 0.8973 - val_loss: 0.7150 - val_accuracy: 0.7873\n",
            "Epoch 26/35\n",
            "38/38 [==============================] - 35s 925ms/step - loss: 0.1012 - accuracy: 0.8839 - val_loss: 0.6229 - val_accuracy: 0.7722\n",
            "Epoch 27/35\n",
            "38/38 [==============================] - 35s 926ms/step - loss: 0.1047 - accuracy: 0.8872 - val_loss: 0.8294 - val_accuracy: 0.7906\n",
            "Epoch 28/35\n",
            "38/38 [==============================] - 35s 929ms/step - loss: 0.0853 - accuracy: 0.8885 - val_loss: 0.7229 - val_accuracy: 0.7755\n",
            "Epoch 29/35\n",
            "38/38 [==============================] - 35s 922ms/step - loss: 0.1033 - accuracy: 0.8860 - val_loss: 0.6299 - val_accuracy: 0.7806\n",
            "Epoch 30/35\n",
            "38/38 [==============================] - 35s 919ms/step - loss: 0.0896 - accuracy: 0.8818 - val_loss: 0.7135 - val_accuracy: 0.7739\n",
            "Epoch 31/35\n",
            "38/38 [==============================] - 35s 920ms/step - loss: 0.0882 - accuracy: 0.8776 - val_loss: 0.7438 - val_accuracy: 0.7789\n",
            "Epoch 32/35\n",
            "38/38 [==============================] - 35s 911ms/step - loss: 0.0814 - accuracy: 0.8855 - val_loss: 0.7637 - val_accuracy: 0.7906\n",
            "Epoch 33/35\n",
            "38/38 [==============================] - 35s 912ms/step - loss: 0.0821 - accuracy: 0.8935 - val_loss: 0.7116 - val_accuracy: 0.7873\n",
            "Epoch 34/35\n",
            "38/38 [==============================] - 35s 916ms/step - loss: 0.0738 - accuracy: 0.8839 - val_loss: 0.6940 - val_accuracy: 0.7889\n",
            "Epoch 35/35\n",
            "38/38 [==============================] - 35s 914ms/step - loss: 0.0885 - accuracy: 0.8813 - val_loss: 0.7331 - val_accuracy: 0.7739\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cv = KFold(n_splits = 5, shuffle = True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "\n",
        "count = 1\n",
        "for traincv, testcv in cv.split(X):\n",
        "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "    #print(y_train)\n",
        "    train_essays = X_train['Lyrics']\n",
        "    test_essays = X_test['Lyrics']\n",
        "    num_features = 512\n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "    clean_train_essays = []\n",
        "    clean_test_essays=[]\n",
        "    #essays=train_essays\n",
        "    sentences=[]\n",
        "    l1=[]\n",
        "    l2=[]\n",
        "    for essay in train_essays:\n",
        "      sentences += essay_to_sentences(essay, remove_stopwords = False)\n",
        "      #print(sentences)\n",
        "    for essay in test_essays:\n",
        "      sentences += essay_to_sentences(essay, remove_stopwords = False)\n",
        "    for essay_v in train_essays:\n",
        "      l1.append(len(sent_tokenize(essay_v)))\n",
        "      clean_train_essays.append(essay_to_sentences(essay_v, remove_stopwords=True))\n",
        "      #print(clean_train_essays)\n",
        "    a=np.array(l1)\n",
        "    print(max(a))\n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, num_features,a)\n",
        "    for essay_v in test_essays:\n",
        "      l2.append(len(sent_tokenize(essay_v)))\n",
        "      clean_test_essays.append(essay_to_sentences(essay_v, remove_stopwords=True))\n",
        "    b=np.array(l2)\n",
        "    testDataVecs=getAvgFeatureVecs(clean_test_essays, num_features,b)\n",
        "    trainDataVecs=np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    trainDataVecs=np.reshape(trainDataVecs,(trainDataVecs.shape[0],1,trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    #print(b)\n",
        "    #lstm_model = get_model()\n",
        "    X_train, X_val, y_train, y_val = train_test_split(trainDataVecs, y_train, test_size=0.2, random_state=1)\n",
        "    lstm_model = get_model()\n",
        "    history=lstm_model.fit(X_train, y_train, batch_size=64, epochs=35,validation_data=(X_val, y_val))\n",
        "    #history=lstm_model.fit(trainDataVecs, y_train, batch_size=90, epochs=15)\n",
        "    y_pred=(lstm_model.predict(testDataVecs))\n",
        "    #print(y_pred)\n",
        "    # Save any one of the 5 models.\n",
        "    #if count == 6:\n",
        "      #break\n",
        "         #lstm_model.save('./model_weights/final_lstm.h5')\n",
        "    \n",
        "    # Round y_pred to the nearest integer.\n",
        "    y_pred = np.around(y_pred)\n",
        "    #print(y_pred)\n",
        "    \n",
        "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "    #result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
        "    #print(\"Kappa Score: {}\".format(result))\n",
        "    #results.append(result)\n",
        "\n",
        "    #count += 1\n",
        "   \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstm_model.save('./model_weights/final_lstm.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vckSjRQkTK3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(1,36)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "dee84939e8edcdc0c40c49a97935151e1334e3d0558b4b47e6804a9dbd6a7406"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
